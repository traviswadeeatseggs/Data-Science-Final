{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('LosAngeles_Earthquake_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>mag</th>\n",
       "      <th>clustering_coefficient_30_days</th>\n",
       "      <th>std_mag_30_days</th>\n",
       "      <th>rolling_mean_depth_30_days</th>\n",
       "      <th>earthquakes_last_30_days</th>\n",
       "      <th>b_value</th>\n",
       "      <th>b_value_increment_i_i2</th>\n",
       "      <th>b_value_increment_i2_i4</th>\n",
       "      <th>b_value_increment_i4_i6</th>\n",
       "      <th>b_value_increment_i6_i8</th>\n",
       "      <th>b_value_increment_i8_i10</th>\n",
       "      <th>max_mag_last_week</th>\n",
       "      <th>eta</th>\n",
       "      <th>delta_M</th>\n",
       "      <th>elapsed_time</th>\n",
       "      <th>coefficient_of_variation</th>\n",
       "      <th>dE1_2</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.736167</td>\n",
       "      <td>-117.543667</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.761985</td>\n",
       "      <td>0.450064</td>\n",
       "      <td>10.010000</td>\n",
       "      <td>62</td>\n",
       "      <td>0.696878</td>\n",
       "      <td>-0.015781</td>\n",
       "      <td>-0.016952</td>\n",
       "      <td>0.027703</td>\n",
       "      <td>0.045957</td>\n",
       "      <td>0.068377</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.171183</td>\n",
       "      <td>-1.191173</td>\n",
       "      <td>1.826028e+06</td>\n",
       "      <td>1.030479</td>\n",
       "      <td>60072.253071</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.231167</td>\n",
       "      <td>-117.613333</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.763917</td>\n",
       "      <td>0.447643</td>\n",
       "      <td>9.956730</td>\n",
       "      <td>63</td>\n",
       "      <td>0.709632</td>\n",
       "      <td>0.005751</td>\n",
       "      <td>-0.005374</td>\n",
       "      <td>0.022239</td>\n",
       "      <td>0.063360</td>\n",
       "      <td>0.081494</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.171273</td>\n",
       "      <td>-1.136158</td>\n",
       "      <td>1.719504e+06</td>\n",
       "      <td>1.018022</td>\n",
       "      <td>59804.049628</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.448333</td>\n",
       "      <td>-119.028667</td>\n",
       "      <td>2.77</td>\n",
       "      <td>0.759888</td>\n",
       "      <td>0.471666</td>\n",
       "      <td>9.982750</td>\n",
       "      <td>64</td>\n",
       "      <td>0.702969</td>\n",
       "      <td>0.006091</td>\n",
       "      <td>-0.009690</td>\n",
       "      <td>-0.010861</td>\n",
       "      <td>0.033795</td>\n",
       "      <td>0.052048</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.171953</td>\n",
       "      <td>-1.164648</td>\n",
       "      <td>1.626713e+06</td>\n",
       "      <td>1.040813</td>\n",
       "      <td>59828.224358</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33.987667</td>\n",
       "      <td>-117.246500</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.763414</td>\n",
       "      <td>0.473813</td>\n",
       "      <td>10.037185</td>\n",
       "      <td>65</td>\n",
       "      <td>0.679434</td>\n",
       "      <td>-0.030197</td>\n",
       "      <td>-0.024446</td>\n",
       "      <td>-0.035571</td>\n",
       "      <td>-0.007958</td>\n",
       "      <td>0.033163</td>\n",
       "      <td>2.77</td>\n",
       "      <td>0.163891</td>\n",
       "      <td>-1.269765</td>\n",
       "      <td>1.643494e+06</td>\n",
       "      <td>1.032048</td>\n",
       "      <td>66772.751598</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34.453500</td>\n",
       "      <td>-117.954333</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.760808</td>\n",
       "      <td>0.477744</td>\n",
       "      <td>10.007470</td>\n",
       "      <td>66</td>\n",
       "      <td>0.721180</td>\n",
       "      <td>0.018210</td>\n",
       "      <td>0.024302</td>\n",
       "      <td>0.008521</td>\n",
       "      <td>0.007349</td>\n",
       "      <td>0.052005</td>\n",
       "      <td>2.77</td>\n",
       "      <td>0.170929</td>\n",
       "      <td>-1.088020</td>\n",
       "      <td>1.686714e+06</td>\n",
       "      <td>1.045357</td>\n",
       "      <td>59653.522777</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22894</th>\n",
       "      <td>34.429167</td>\n",
       "      <td>-118.596667</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.820414</td>\n",
       "      <td>0.609210</td>\n",
       "      <td>10.222676</td>\n",
       "      <td>142</td>\n",
       "      <td>0.688919</td>\n",
       "      <td>-0.016334</td>\n",
       "      <td>0.018297</td>\n",
       "      <td>0.007138</td>\n",
       "      <td>-0.017251</td>\n",
       "      <td>-0.012914</td>\n",
       "      <td>2.07</td>\n",
       "      <td>0.167934</td>\n",
       "      <td>-0.856539</td>\n",
       "      <td>7.821234e+05</td>\n",
       "      <td>1.227976</td>\n",
       "      <td>49516.413796</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22895</th>\n",
       "      <td>33.843500</td>\n",
       "      <td>-117.619833</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.821639</td>\n",
       "      <td>0.610980</td>\n",
       "      <td>10.216084</td>\n",
       "      <td>143</td>\n",
       "      <td>0.691772</td>\n",
       "      <td>-0.016933</td>\n",
       "      <td>-0.011881</td>\n",
       "      <td>0.018447</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>-0.010288</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.167642</td>\n",
       "      <td>-0.843768</td>\n",
       "      <td>7.809422e+05</td>\n",
       "      <td>1.243281</td>\n",
       "      <td>49507.751138</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22896</th>\n",
       "      <td>33.972833</td>\n",
       "      <td>-118.757833</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.818340</td>\n",
       "      <td>0.609619</td>\n",
       "      <td>10.234167</td>\n",
       "      <td>144</td>\n",
       "      <td>0.579214</td>\n",
       "      <td>-0.109705</td>\n",
       "      <td>-0.126039</td>\n",
       "      <td>-0.091408</td>\n",
       "      <td>-0.102567</td>\n",
       "      <td>-0.126956</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.178431</td>\n",
       "      <td>-1.293035</td>\n",
       "      <td>7.828122e+05</td>\n",
       "      <td>1.250434</td>\n",
       "      <td>48991.210075</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22897</th>\n",
       "      <td>34.215833</td>\n",
       "      <td>-117.456833</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.818106</td>\n",
       "      <td>0.608019</td>\n",
       "      <td>10.235931</td>\n",
       "      <td>145</td>\n",
       "      <td>0.571741</td>\n",
       "      <td>-0.120031</td>\n",
       "      <td>-0.136964</td>\n",
       "      <td>-0.131912</td>\n",
       "      <td>-0.101584</td>\n",
       "      <td>-0.119151</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.179451</td>\n",
       "      <td>-1.341173</td>\n",
       "      <td>7.821920e+05</td>\n",
       "      <td>1.237475</td>\n",
       "      <td>49197.551909</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22898</th>\n",
       "      <td>34.138500</td>\n",
       "      <td>-117.545500</td>\n",
       "      <td>1.62</td>\n",
       "      <td>0.817085</td>\n",
       "      <td>0.580213</td>\n",
       "      <td>10.121528</td>\n",
       "      <td>144</td>\n",
       "      <td>0.578905</td>\n",
       "      <td>-0.000309</td>\n",
       "      <td>-0.110014</td>\n",
       "      <td>-0.126348</td>\n",
       "      <td>-0.091717</td>\n",
       "      <td>-0.102876</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.177966</td>\n",
       "      <td>-1.295000</td>\n",
       "      <td>7.865913e+05</td>\n",
       "      <td>1.234690</td>\n",
       "      <td>49095.913034</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22899 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        latitude   longitude   mag  clustering_coefficient_30_days  \\\n",
       "0      33.736167 -117.543667  1.29                        0.761985   \n",
       "1      34.231167 -117.613333  1.24                        0.763917   \n",
       "2      34.448333 -119.028667  2.77                        0.759888   \n",
       "3      33.987667 -117.246500  0.92                        0.763414   \n",
       "4      34.453500 -117.954333  0.82                        0.760808   \n",
       "...          ...         ...   ...                             ...   \n",
       "22894  34.429167 -118.596667  0.92                        0.820414   \n",
       "22895  33.843500 -117.619833  0.54                        0.821639   \n",
       "22896  33.972833 -118.757833  1.73                        0.818340   \n",
       "22897  34.215833 -117.456833  1.06                        0.818106   \n",
       "22898  34.138500 -117.545500  1.62                        0.817085   \n",
       "\n",
       "       std_mag_30_days  rolling_mean_depth_30_days  earthquakes_last_30_days  \\\n",
       "0             0.450064                   10.010000                        62   \n",
       "1             0.447643                    9.956730                        63   \n",
       "2             0.471666                    9.982750                        64   \n",
       "3             0.473813                   10.037185                        65   \n",
       "4             0.477744                   10.007470                        66   \n",
       "...                ...                         ...                       ...   \n",
       "22894         0.609210                   10.222676                       142   \n",
       "22895         0.610980                   10.216084                       143   \n",
       "22896         0.609619                   10.234167                       144   \n",
       "22897         0.608019                   10.235931                       145   \n",
       "22898         0.580213                   10.121528                       144   \n",
       "\n",
       "        b_value  b_value_increment_i_i2  b_value_increment_i2_i4  \\\n",
       "0      0.696878               -0.015781                -0.016952   \n",
       "1      0.709632                0.005751                -0.005374   \n",
       "2      0.702969                0.006091                -0.009690   \n",
       "3      0.679434               -0.030197                -0.024446   \n",
       "4      0.721180                0.018210                 0.024302   \n",
       "...         ...                     ...                      ...   \n",
       "22894  0.688919               -0.016334                 0.018297   \n",
       "22895  0.691772               -0.016933                -0.011881   \n",
       "22896  0.579214               -0.109705                -0.126039   \n",
       "22897  0.571741               -0.120031                -0.136964   \n",
       "22898  0.578905               -0.000309                -0.110014   \n",
       "\n",
       "       b_value_increment_i4_i6  b_value_increment_i6_i8  \\\n",
       "0                     0.027703                 0.045957   \n",
       "1                     0.022239                 0.063360   \n",
       "2                    -0.010861                 0.033795   \n",
       "3                    -0.035571                -0.007958   \n",
       "4                     0.008521                 0.007349   \n",
       "...                        ...                      ...   \n",
       "22894                 0.007138                -0.017251   \n",
       "22895                 0.018447                 0.000880   \n",
       "22896                -0.091408                -0.102567   \n",
       "22897                -0.131912                -0.101584   \n",
       "22898                -0.126348                -0.091717   \n",
       "\n",
       "       b_value_increment_i8_i10  max_mag_last_week       eta   delta_M  \\\n",
       "0                      0.068377               1.70  0.171183 -1.191173   \n",
       "1                      0.081494               1.70  0.171273 -1.136158   \n",
       "2                      0.052048               1.70  0.171953 -1.164648   \n",
       "3                      0.033163               2.77  0.163891 -1.269765   \n",
       "4                      0.052005               2.77  0.170929 -1.088020   \n",
       "...                         ...                ...       ...       ...   \n",
       "22894                 -0.012914               2.07  0.167934 -0.856539   \n",
       "22895                 -0.010288               1.67  0.167642 -0.843768   \n",
       "22896                 -0.126956               1.67  0.178431 -1.293035   \n",
       "22897                 -0.119151               1.73  0.179451 -1.341173   \n",
       "22898                 -0.102876               1.73  0.177966 -1.295000   \n",
       "\n",
       "       elapsed_time  coefficient_of_variation         dE1_2  class  \n",
       "0      1.826028e+06                  1.030479  60072.253071      3  \n",
       "1      1.719504e+06                  1.018022  59804.049628      3  \n",
       "2      1.626713e+06                  1.040813  59828.224358      3  \n",
       "3      1.643494e+06                  1.032048  66772.751598      3  \n",
       "4      1.686714e+06                  1.045357  59653.522777      3  \n",
       "...             ...                       ...           ...    ...  \n",
       "22894  7.821234e+05                  1.227976  49516.413796      1  \n",
       "22895  7.809422e+05                  1.243281  49507.751138      1  \n",
       "22896  7.828122e+05                  1.250434  48991.210075      1  \n",
       "22897  7.821920e+05                  1.237475  49197.551909      1  \n",
       "22898  7.865913e+05                  1.234690  49095.913034      1  \n",
       "\n",
       "[22899 rows x 20 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['latitude', 'longitude', 'mag', 'clustering_coefficient_30_days',\n",
       "       'std_mag_30_days', 'rolling_mean_depth_30_days',\n",
       "       'earthquakes_last_30_days', 'b_value', 'b_value_increment_i_i2',\n",
       "       'b_value_increment_i2_i4', 'b_value_increment_i4_i6',\n",
       "       'b_value_increment_i6_i8', 'b_value_increment_i8_i10',\n",
       "       'max_mag_last_week', 'eta', 'delta_M', 'elapsed_time',\n",
       "       'coefficient_of_variation', 'dE1_2', 'class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.iloc[:, 2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.29, 1.24, 2.77, ..., 1.73, 1.06, 1.62])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dbest\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(activation=\"relu\", input_dim=20, units=6, kernel_initializer=\"uniform\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 710us/step - accuracy: 0.0112 - loss: -24.6721\n",
      "Epoch 2/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 682us/step - accuracy: 0.0097 - loss: -660.1013\n",
      "Epoch 3/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 675us/step - accuracy: 0.0098 - loss: -2861.0110\n",
      "Epoch 4/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689us/step - accuracy: 0.0082 - loss: -6875.6890\n",
      "Epoch 5/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687us/step - accuracy: 0.0094 - loss: -13256.2080\n",
      "Epoch 6/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 697us/step - accuracy: 0.0092 - loss: -21714.1152\n",
      "Epoch 7/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 682us/step - accuracy: 0.0095 - loss: -34325.4023\n",
      "Epoch 8/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 692us/step - accuracy: 0.0091 - loss: -49699.5820\n",
      "Epoch 9/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 687us/step - accuracy: 0.0104 - loss: -68112.8438\n",
      "Epoch 10/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 691us/step - accuracy: 0.0088 - loss: -89445.7031\n",
      "Epoch 11/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 680us/step - accuracy: 0.0088 - loss: -119021.4922\n",
      "Epoch 12/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 686us/step - accuracy: 0.0097 - loss: -149746.0312\n",
      "Epoch 13/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - accuracy: 0.0079 - loss: -186994.7500\n",
      "Epoch 14/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 683us/step - accuracy: 0.0088 - loss: -228732.9219\n",
      "Epoch 15/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - accuracy: 0.0096 - loss: -280202.4688\n",
      "Epoch 16/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.0095 - loss: -330275.5938\n",
      "Epoch 17/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - accuracy: 0.0100 - loss: -385210.8750\n",
      "Epoch 18/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695us/step - accuracy: 0.0095 - loss: -452707.5625\n",
      "Epoch 19/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - accuracy: 0.0101 - loss: -523678.7812\n",
      "Epoch 20/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 685us/step - accuracy: 0.0083 - loss: -621778.3750\n",
      "Epoch 21/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695us/step - accuracy: 0.0113 - loss: -693854.6875\n",
      "Epoch 22/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step - accuracy: 0.0098 - loss: -801587.6875\n",
      "Epoch 23/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695us/step - accuracy: 0.0091 - loss: -921549.3750\n",
      "Epoch 24/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step - accuracy: 0.0084 - loss: -1039918.7500\n",
      "Epoch 25/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695us/step - accuracy: 0.0095 - loss: -1171583.3750\n",
      "Epoch 26/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689us/step - accuracy: 0.0092 - loss: -1292690.6250\n",
      "Epoch 27/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 691us/step - accuracy: 0.0090 - loss: -1451651.7500\n",
      "Epoch 28/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 685us/step - accuracy: 0.0101 - loss: -1601446.2500\n",
      "Epoch 29/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689us/step - accuracy: 0.0095 - loss: -1678382.7500\n",
      "Epoch 30/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 698us/step - accuracy: 0.0100 - loss: -1936815.0000\n",
      "Epoch 31/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 713us/step - accuracy: 0.0094 - loss: -2164982.7500\n",
      "Epoch 32/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 703us/step - accuracy: 0.0086 - loss: -2382392.7500\n",
      "Epoch 33/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 702us/step - accuracy: 0.0110 - loss: -2518993.5000\n",
      "Epoch 34/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - accuracy: 0.0091 - loss: -2801797.7500\n",
      "Epoch 35/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677us/step - accuracy: 0.0087 - loss: -3071223.0000\n",
      "Epoch 36/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 697us/step - accuracy: 0.0094 - loss: -3255561.0000\n",
      "Epoch 37/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - accuracy: 0.0089 - loss: -3489850.0000\n",
      "Epoch 38/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695us/step - accuracy: 0.0105 - loss: -3685781.2500\n",
      "Epoch 39/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 709us/step - accuracy: 0.0094 - loss: -4091391.7500\n",
      "Epoch 40/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - accuracy: 0.0090 - loss: -4350111.0000\n",
      "Epoch 41/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 703us/step - accuracy: 0.0109 - loss: -4749492.0000\n",
      "Epoch 42/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 696us/step - accuracy: 0.0096 - loss: -5069296.0000\n",
      "Epoch 43/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 712us/step - accuracy: 0.0088 - loss: -5447630.5000\n",
      "Epoch 44/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.0093 - loss: -5682309.0000\n",
      "Epoch 45/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 696us/step - accuracy: 0.0097 - loss: -6107580.5000\n",
      "Epoch 46/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 710us/step - accuracy: 0.0087 - loss: -6530334.0000\n",
      "Epoch 47/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 714us/step - accuracy: 0.0092 - loss: -7099295.5000\n",
      "Epoch 48/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 696us/step - accuracy: 0.0097 - loss: -7395652.5000\n",
      "Epoch 49/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 692us/step - accuracy: 0.0083 - loss: -7862949.0000\n",
      "Epoch 50/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - accuracy: 0.0100 - loss: -8198181.0000\n",
      "Epoch 51/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 703us/step - accuracy: 0.0093 - loss: -8755802.0000\n",
      "Epoch 52/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 692us/step - accuracy: 0.0088 - loss: -9489255.0000\n",
      "Epoch 53/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695us/step - accuracy: 0.0100 - loss: -10007953.0000\n",
      "Epoch 54/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - accuracy: 0.0095 - loss: -10036663.0000\n",
      "Epoch 55/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 698us/step - accuracy: 0.0089 - loss: -10725787.0000\n",
      "Epoch 56/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step - accuracy: 0.0083 - loss: -11798290.0000\n",
      "Epoch 57/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - accuracy: 0.0100 - loss: -11528958.0000\n",
      "Epoch 58/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695us/step - accuracy: 0.0095 - loss: -12798596.0000\n",
      "Epoch 59/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 718us/step - accuracy: 0.0100 - loss: -12980237.0000\n",
      "Epoch 60/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 693us/step - accuracy: 0.0097 - loss: -13763329.0000\n",
      "Epoch 61/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 697us/step - accuracy: 0.0097 - loss: -14348489.0000\n",
      "Epoch 62/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 703us/step - accuracy: 0.0095 - loss: -14978477.0000\n",
      "Epoch 63/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 701us/step - accuracy: 0.0099 - loss: -16154494.0000\n",
      "Epoch 64/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 699us/step - accuracy: 0.0086 - loss: -16979874.0000\n",
      "Epoch 65/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 743us/step - accuracy: 0.0092 - loss: -17507422.0000\n",
      "Epoch 66/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 793us/step - accuracy: 0.0088 - loss: -18458386.0000\n",
      "Epoch 67/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - accuracy: 0.0089 - loss: -19836642.0000\n",
      "Epoch 68/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 717us/step - accuracy: 0.0103 - loss: -19671150.0000\n",
      "Epoch 69/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - accuracy: 0.0096 - loss: -20465544.0000\n",
      "Epoch 70/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 708us/step - accuracy: 0.0081 - loss: -21616704.0000\n",
      "Epoch 71/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - accuracy: 0.0084 - loss: -22454576.0000\n",
      "Epoch 72/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 719us/step - accuracy: 0.0093 - loss: -23635736.0000\n",
      "Epoch 73/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step - accuracy: 0.0103 - loss: -24594210.0000\n",
      "Epoch 74/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695us/step - accuracy: 0.0093 - loss: -26158432.0000\n",
      "Epoch 75/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 715us/step - accuracy: 0.0094 - loss: -27393054.0000\n",
      "Epoch 76/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 731us/step - accuracy: 0.0105 - loss: -28147762.0000\n",
      "Epoch 77/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 696us/step - accuracy: 0.0097 - loss: -29354148.0000\n",
      "Epoch 78/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 716us/step - accuracy: 0.0096 - loss: -29479574.0000\n",
      "Epoch 79/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 705us/step - accuracy: 0.0088 - loss: -30918966.0000\n",
      "Epoch 80/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695us/step - accuracy: 0.0085 - loss: -32220330.0000\n",
      "Epoch 81/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 707us/step - accuracy: 0.0090 - loss: -32784452.0000\n",
      "Epoch 82/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 700us/step - accuracy: 0.0085 - loss: -33724420.0000\n",
      "Epoch 83/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729us/step - accuracy: 0.0093 - loss: -35156576.0000\n",
      "Epoch 84/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 848us/step - accuracy: 0.0083 - loss: -36668308.0000\n",
      "Epoch 85/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - accuracy: 0.0101 - loss: -37235388.0000\n",
      "Epoch 86/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 724us/step - accuracy: 0.0092 - loss: -39374596.0000\n",
      "Epoch 87/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 788us/step - accuracy: 0.0092 - loss: -40152624.0000\n",
      "Epoch 88/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 900us/step - accuracy: 0.0092 - loss: -42739396.0000\n",
      "Epoch 89/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 979us/step - accuracy: 0.0098 - loss: -43266944.0000\n",
      "Epoch 90/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 816us/step - accuracy: 0.0105 - loss: -44909412.0000\n",
      "Epoch 91/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 810us/step - accuracy: 0.0080 - loss: -46752252.0000\n",
      "Epoch 92/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 820us/step - accuracy: 0.0098 - loss: -46688888.0000\n",
      "Epoch 93/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 835us/step - accuracy: 0.0092 - loss: -50156392.0000\n",
      "Epoch 94/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 810us/step - accuracy: 0.0090 - loss: -50560560.0000\n",
      "Epoch 95/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 815us/step - accuracy: 0.0082 - loss: -52417336.0000\n",
      "Epoch 96/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 818us/step - accuracy: 0.0085 - loss: -53912604.0000\n",
      "Epoch 97/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 817us/step - accuracy: 0.0083 - loss: -54732280.0000\n",
      "Epoch 98/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 838us/step - accuracy: 0.0090 - loss: -57545752.0000\n",
      "Epoch 99/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 817us/step - accuracy: 0.0095 - loss: -60442260.0000\n",
      "Epoch 100/100\n",
      "\u001b[1m1832/1832\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 811us/step - accuracy: 0.0090 - loss: -60961252.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x189bafda5d0>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m144/144\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[124], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[1;32m----> 2\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test, y_pred)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(cm)\n\u001b[0;32m      4\u001b[0m tn, fp, fn, tp \u001b[38;5;241m=\u001b[39m cm\u001b[38;5;241m.\u001b[39mravel()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:326\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    232\u001b[0m     {\n\u001b[0;32m    233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    242\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    243\u001b[0m ):\n\u001b[0;32m    244\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[0;32m    245\u001b[0m \n\u001b[0;32m    246\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 326\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous and binary targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "accuracy = (tn + tp) / (tn + tp + fn + fp)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
